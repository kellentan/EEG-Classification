{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import eeg_utils\n",
    "import numpy as np\n",
    "from eeg_utils import *\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEG Data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "# Visualize EEG Data Shapes\n",
    "print(\"Training/Valid data shape: {}\".format(X_train_valid.shape))\n",
    "print(\"Test data shape: {}\".format(X_test.shape))\n",
    "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))\n",
    "print(\"Test target shape: {}\".format(y_test.shape))\n",
    "print(\"Person train/valid shape: {}\".format(person_train_valid.shape))\n",
    "print(\"Person test shape: {}\".format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [RUN IFF] Trained on Subject One ONLY\n",
    "patient_data = []\n",
    "patient_truths = []\n",
    "\n",
    "test_data = []\n",
    "test_truths = []\n",
    "\n",
    "for patient in np.unique(person_train_valid):\n",
    "    idx = np.where(person_train_valid == patient)[0]\n",
    "    patient_data.append(X_train_valid[idx, :, :])\n",
    "    patient_truths.append(y_train_valid[idx])\n",
    "    pass\n",
    "\n",
    "# ALso split the testing set, as we want to optimize on subject one\n",
    "for patient in np.unique(person_test):\n",
    "    idx = np.where(person_test == patient)[0]\n",
    "    test_data.append(X_test[idx, :, :])\n",
    "    test_truths.append(y_test[idx])\n",
    "    pass\n",
    "\n",
    "# Store actual test data\n",
    "X_test_actual = X_test\n",
    "y_test_actual = y_test\n",
    "\n",
    "X_train_valid = patient_data[0]\n",
    "y_train_valid = patient_truths[0]\n",
    "X_test = test_data[0]\n",
    "y_test = test_truths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "data_config = {\"Duplicate\": 2, \"Mu\": 0.0, \"Sigma\": 0.5,\n",
    "               \"Sample\": False, \"Sample_Step\": 5, \"Attention\": False, \"Swap\": True}\n",
    "X_train_valid, y_train_valid, X_test, y_test = preprocess_data(X_train_valid,\n",
    "                                                               y_train_valid,\n",
    "                                                               X_test,\n",
    "                                                               y_test, \n",
    "                                                               data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training/Validation Data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid,\n",
    "                                                      y_train_valid,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim Data pre-Model\n",
    "X_train_5d = X_train[:, :500, :, :]\n",
    "X_valid_5d = X_valid[:, :500, :, :]\n",
    "X_test_5d = X_test[:, :500, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Optimal Model\n",
    "model_name = \"./CNN_Train_One\" # Despite its name, this is still the same CRNN as CRNN_Train_All\n",
    "optim_model = keras.models.load_model(model_name) # Model that was trained on subject one only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 16ms/step - loss: 0.4268 - accuracy: 0.9815\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0345 - accuracy: 0.8105\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.5524 - accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5524128675460815, 0.699999988079071]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate all results (Train on one subject, test on one subject)\n",
    "optim_model.evaluate(X_train_5d, y_train) # 98.15%\n",
    "optim_model.evaluate(X_valid_5d, y_valid) # 81.05%\n",
    "optim_model.evaluate(X_test_5d, y_test) # 70.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all testing data\n",
    "X_test_actual = X_test_actual.reshape((X_test_actual.shape)[0],\n",
    "                                     (X_test_actual.shape)[1],\n",
    "                                     (X_test_actual.shape)[2], 1)\n",
    "X_test_actual = np.swapaxes(np.swapaxes(X_test_actual, 1, 2), 2, 3)\n",
    "\n",
    "# Preprocess all testing truths\n",
    "y_test_actual = y_test_actual - 769\n",
    "y_test_actual = to_categorical(y_test_actual, 4)\n",
    "\n",
    "# Separate Data by Patient\n",
    "patient_data = []\n",
    "patient_truths = []\n",
    "\n",
    "for patient in np.unique(person_test):\n",
    "    idx = np.where(person_test == patient)[0]\n",
    "    patient_data.append(X_test_actual[idx, :500, :, :])\n",
    "    patient_truths.append(y_test_actual[idx])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 1.5524 - accuracy: 0.7000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.5323 - accuracy: 0.3000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.7379 - accuracy: 0.4200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.7032 - accuracy: 0.3200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.7539 - accuracy: 0.2553\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.6770 - accuracy: 0.2857\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.3308 - accuracy: 0.3800\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.7654 - accuracy: 0.3000\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.5758 - accuracy: 0.3191\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on each patient (Train on subject one, Test on a single subject)\n",
    "for i in range(len(patient_data)):\n",
    "    optim_model.evaluate(patient_data[i], patient_truths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel Parameters: 122 Epochs\\n    - Data augmented CRNN with doubly stacked LSTM layer\\n    - Regularization : 0.006\\n    - Learning Rate : 0.001\\n    - Attention : False\\n    - Time Points : 500\\n    - Kernel : (10, 1)\\n    - Sample : False\\n    - Dropout : 0.5\\n    - Pool : (3, 1)\\n    - Duplicate : 2\\n    - Sigma : 0.5\\n    - Mu : 0.0\\n    \\n    N.B. For importance of the parameters above, see CRNN Model notebook for architecture\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model Parameters: 122 Epochs\n",
    "    - Data augmented CRNN with doubly stacked LSTM layer\n",
    "    - Regularization : 0.006\n",
    "    - Learning Rate : 0.001\n",
    "    - Attention : False\n",
    "    - Time Points : 500\n",
    "    - Kernel : (10, 1)\n",
    "    - Sample : False\n",
    "    - Dropout : 0.5\n",
    "    - Pool : (3, 1)\n",
    "    - Duplicate : 2\n",
    "    - Sigma : 0.5\n",
    "    - Mu : 0.0\n",
    "    \n",
    "    N.B. For importance of the parameters above, see CRNN Model notebook for architecture\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
