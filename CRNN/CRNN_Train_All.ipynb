{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import eeg_utils\n",
    "import numpy as np\n",
    "from eeg_utils import *\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEG Data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "# Visualize EEG Data Shapes\n",
    "print(\"Training/Valid data shape: {}\".format(X_train_valid.shape))\n",
    "print(\"Test data shape: {}\".format(X_test.shape))\n",
    "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))\n",
    "print(\"Test target shape: {}\".format(y_test.shape))\n",
    "print(\"Person train/valid shape: {}\".format(person_train_valid.shape))\n",
    "print(\"Person test shape: {}\".format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "data_config = {\"Duplicate\": 2, \"Mu\": 0.0, \"Sigma\": 0.5,\n",
    "               \"Sample\": False, \"Sample_Step\": 5, \"Attention\": False, \"Swap\": True}\n",
    "X_train_valid, y_train_valid, X_test, y_test = preprocess_data(X_train_valid,\n",
    "                                                               y_train_valid,\n",
    "                                                               X_test,\n",
    "                                                               y_test, \n",
    "                                                               data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training/Validation Data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid,\n",
    "                                                      y_train_valid,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim Data pre-Model\n",
    "X_train_5d = X_train[:, :500, :, :]\n",
    "X_valid_5d = X_valid[:, :500, :, :]\n",
    "X_test_5d = X_test[:, :500, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Optimal Model\n",
    "model_name = \"./CRNN_Train_All\"\n",
    "optim_model = keras.models.load_model(model_name) # Model that was trained on all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 2s 16ms/step - loss: 0.4393 - accuracy: 0.9551\n",
      "27/27 [==============================] - 0s 18ms/step - loss: 0.7134 - accuracy: 0.8853\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.3565 - accuracy: 0.7043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3564612865447998, 0.7042889595031738]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Results (Train on all subjects, Test on all subjects)\n",
    "optim_model.evaluate(X_train_5d, y_train) # 95.51%\n",
    "optim_model.evaluate(X_valid_5d, y_valid) # 88.53%\n",
    "optim_model.evaluate(X_test_5d, y_test) # 70.43%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data by patient\n",
    "patient_data = []\n",
    "patient_truths = []\n",
    "\n",
    "for patient in np.unique(person_test):\n",
    "    idx = np.where(person_test == patient)[0]\n",
    "    patient_data.append(X_test_5d[idx, :, :, :])\n",
    "    patient_truths.append(y_test[idx])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6901 - accuracy: 0.6800\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.6704 - accuracy: 0.6200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.3635 - accuracy: 0.6800\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8142 - accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1189 - accuracy: 0.7447\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.6505 - accuracy: 0.6531\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3018 - accuracy: 0.7400\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4037 - accuracy: 0.7000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1758 - accuracy: 0.7234\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on each patient (Train on all subjects, Test on a single subject)\n",
    "for i in range(len(patient_data)):\n",
    "    optim_model.evaluate(patient_data[i], patient_truths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel Parameters:\\n    - Data augmented CRNN with doubly stacked LSTM layer\\n    - Regularization : 0.006\\n    - Learning Rate : 0.001\\n    - Attention : False\\n    - Time Points : 500\\n    - Kernel : (10, 1)\\n    - Sample : False\\n    - Dropout : 0.5\\n    - Pool : (3, 1)\\n    - Duplicate : 2\\n    - Sigma : 0.5\\n    - Mu : 0.0\\n    \\n    N.B. For importance of the parameters above, see CRNN Model notebook for architecture\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model Parameters: 147 Epochs\n",
    "    - Data augmented CRNN with doubly stacked LSTM layer\n",
    "    - Regularization : 0.006\n",
    "    - Learning Rate : 0.001\n",
    "    - Attention : False\n",
    "    - Time Points : 500\n",
    "    - Kernel : (10, 1)\n",
    "    - Sample : False\n",
    "    - Dropout : 0.5\n",
    "    - Pool : (3, 1)\n",
    "    - Duplicate : 2\n",
    "    - Sigma : 0.5\n",
    "    - Mu : 0.0\n",
    "    \n",
    "    N.B. For importance of the parameters above, see CRNN Model notebook for architecture\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
